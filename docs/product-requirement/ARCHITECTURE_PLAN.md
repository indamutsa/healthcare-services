# ğŸ—ï¸ Clinical MLOps Pipeline - Modularization Plan

## ğŸ“‹ Table of Contents
1. [Current State Analysis](#current-state-analysis)
2. [Target Architecture](#target-architecture)
3. [Folder Structure Design](#folder-structure-design)
4. [Layer Responsibilities](#layer-responsibilities)
5. [Service-to-Layer Mapping](#service-to-layer-mapping)
6. [Interface Contracts](#interface-contracts)
7. [Dependency Graph](#dependency-graph)
8. [Migration Strategy](#migration-strategy)

---

## 1. Current State Analysis

### Problems Identified
- **1087 lines** in a single bash script
- **Mixed concerns**: Infrastructure, data flow, ML, orchestration all intertwined
- **Hard to maintain**: Changes require understanding the entire script
- **No clear boundaries**: Functions are tightly coupled
- **Difficult testing**: Cannot test individual components in isolation
- **Poor reusability**: Cannot reuse layer logic elsewhere

### Current Level Structure
```
Level 0: Infrastructure (Base services)
Level 1: Data Ingestion (Kafka producers/consumers)
Level 2: Data Processing (Spark cluster)
Level 3: Feature Engineering
Level 4: ML Pipeline (MLflow, training, serving)
Level 5: Observability (Airflow, Prometheus, etc.)
```

---

## 2. Target Architecture

### Design Principles

**Think of this like a microservices architecture:**
- Each layer = A bounded context (DDD concept)
- Clear separation of concerns
- Single responsibility per layer
- Well-defined interfaces between layers
- Independent deployability and testability

**Analogy for you:**
Imagine each layer as a separate microservice with its own API. The orchestrator is like an API gateway that knows how to call each service's endpoints in the right order.

### Layer-Based Architecture

```
scripts/
â”œâ”€â”€ common/                    # Shared utilities (like a shared library)
â”‚   â”œâ”€â”€ utils.sh              # Common functions (logging, Docker ops)
â”‚   â”œâ”€â”€ config.sh             # Central configuration (service definitions)
â”‚   â””â”€â”€ validation.sh         # Input validation functions
â”‚
â”œâ”€â”€ infrastructure/           # Layer 0: Foundation services
â”‚   â”œâ”€â”€ manage.sh            # Infrastructure orchestration
â”‚   â”œâ”€â”€ init-minio.sh        # MinIO bucket setup
â”‚   â”œâ”€â”€ init-postgres.sh     # Database initialization
â”‚   â””â”€â”€ health-checks.sh     # Infra health validation
â”‚
â”œâ”€â”€ data-ingestion/          # Layer 1: Data collection
â”‚   â”œâ”€â”€ manage.sh            # Ingestion orchestration
â”‚   â”œâ”€â”€ kafka-setup.sh       # Topic creation, producer setup
â”‚   â””â”€â”€ validators.sh        # Data validation rules
â”‚
â”œâ”€â”€ storage/                 # MinIO management utilities
â”‚   â”œâ”€â”€ manage.sh            # Storage operations
â”‚   â”œâ”€â”€ bucket-ops.sh        # Bucket operations (CRUD)
â”‚   â””â”€â”€ data-sync.sh         # Bronze/Silver/Gold sync utilities
â”‚
â”œâ”€â”€ processing-layer/        # Layer 2: Spark processing
â”‚   â”œâ”€â”€ manage.sh            # Spark cluster orchestration
â”‚   â”œâ”€â”€ job-submit.sh        # Spark job submission
â”‚   â””â”€â”€ monitoring.sh        # Spark metrics collection
â”‚
â”œâ”€â”€ ml-layer/                # Layer 3+4: Feature Engineering + ML
â”‚   â”œâ”€â”€ manage.sh            # ML pipeline orchestration
â”‚   â”œâ”€â”€ feature-setup.sh     # Feature store initialization
â”‚   â”œâ”€â”€ mlflow-setup.sh      # MLflow configuration
â”‚   â””â”€â”€ model-ops.sh         # Model deployment utilities
â”‚
â”œâ”€â”€ orchestration-layer/     # Layer 5a: Airflow DAGs
â”‚   â”œâ”€â”€ manage.sh            # Airflow orchestration
â”‚   â”œâ”€â”€ dag-deploy.sh        # DAG deployment
â”‚   â””â”€â”€ scheduler-ops.sh     # Scheduler management
â”‚
â”œâ”€â”€ observability/           # Layer 5b: Monitoring
â”‚   â”œâ”€â”€ manage.sh            # Monitoring orchestration
â”‚   â”œâ”€â”€ metrics-setup.sh     # Prometheus config
â”‚   â”œâ”€â”€ dashboards.sh        # Grafana dashboard import
â”‚   â””â”€â”€ alerts.sh            # Alert configuration
â”‚
â””â”€â”€ pipeline-manager.sh      # ğŸ¯ MAIN ORCHESTRATOR (replaces manage_pipeline.sh)
```

---

## 3. Folder Structure Design

### Common Layer (Shared Library)

**Purpose**: Reusable functions that ALL layers need

```bash
common/
â”œâ”€â”€ utils.sh              # Logging, Docker ops, wait functions
â”œâ”€â”€ config.sh             # Layer definitions, service mappings
â”œâ”€â”€ validation.sh         # Input validation, level checks
â””â”€â”€ README.md             # Documentation for common utilities
```

**Key Functions**:
- `log_info()`, `log_error()`, `log_success()`
- `check_service_running()`, `wait_for_service()`
- `docker_compose_up()`, `docker_compose_down()`
- `validate_layer()`, `get_layer_dependencies()`

### Infrastructure Layer

**Purpose**: Manage foundational services (databases, message queues, object storage)

```bash
infrastructure/
â”œâ”€â”€ manage.sh             # Main entry point (start, stop, status)
â”œâ”€â”€ init-minio.sh         # Create buckets, set policies
â”œâ”€â”€ init-postgres.sh      # Initialize MLflow/Airflow DBs
â”œâ”€â”€ init-kafka.sh         # Create topics, configure brokers
â”œâ”€â”€ health-checks.sh      # Verify all infra services
â””â”€â”€ README.md
```

**Services Managed**: minio, postgres-mlflow, postgres-airflow, redis, kafka, zookeeper

### Data Ingestion Layer

**Purpose**: Manage data producers and consumers

```bash
data-ingestion/
â”œâ”€â”€ manage.sh             # Main entry point
â”œâ”€â”€ kafka-setup.sh        # Configure producers/consumers
â”œâ”€â”€ producer-ops.sh       # Start/stop producers
â”œâ”€â”€ consumer-ops.sh       # Start/stop consumers
â””â”€â”€ README.md
```

**Services Managed**: kafka-producer, kafka-consumer, clinical-mq, clinical-data-gateway

### Storage Layer

**Purpose**: MinIO data lake management utilities

```bash
storage/
â”œâ”€â”€ manage.sh             # Main entry point
â”œâ”€â”€ bucket-ops.sh         # CRUD operations on buckets
â”œâ”€â”€ data-lifecycle.sh     # Bronze â†’ Silver â†’ Gold transitions
â”œâ”€â”€ backup-restore.sh     # Data backup utilities
â””â”€â”€ README.md
```

**Note**: No dedicated services, but provides utilities for data lake operations

### Processing Layer

**Purpose**: Spark cluster and job management

```bash
processing-layer/
â”œâ”€â”€ manage.sh             # Main entry point
â”œâ”€â”€ cluster-ops.sh        # Start/stop Spark cluster
â”œâ”€â”€ job-submit.sh         # Submit Spark jobs
â”œâ”€â”€ job-monitor.sh        # Monitor job status
â””â”€â”€ README.md
```

**Services Managed**: spark-master, spark-worker, spark-streaming, spark-batch

### ML Layer

**Purpose**: Machine learning pipeline (feature engineering + model training/serving)

```bash
ml-layer/
â”œâ”€â”€ manage.sh             # Main entry point
â”œâ”€â”€ feature-setup.sh      # Feature store initialization
â”œâ”€â”€ mlflow-setup.sh       # MLflow server + experiments
â”œâ”€â”€ training-ops.sh       # Model training utilities
â”œâ”€â”€ serving-ops.sh        # Model serving utilities
â””â”€â”€ README.md
```

**Services Managed**: feature-engineering, mlflow-server, ml-training, model-serving

### Orchestration Layer

**Purpose**: Airflow workflow orchestration

```bash
orchestration-layer/
â”œâ”€â”€ manage.sh             # Main entry point
â”œâ”€â”€ airflow-init.sh       # Initialize Airflow (create admin user, etc.)
â”œâ”€â”€ dag-deploy.sh         # Deploy/update DAGs
â”œâ”€â”€ connection-setup.sh   # Configure Airflow connections
â””â”€â”€ README.md
```

**Services Managed**: airflow-init, airflow-webserver, airflow-scheduler

### Observability Layer

**Purpose**: Monitoring, logging, and alerting

```bash
observability/
â”œâ”€â”€ manage.sh             # Main entry point
â”œâ”€â”€ prometheus-setup.sh   # Configure Prometheus targets
â”œâ”€â”€ grafana-setup.sh      # Import dashboards, configure datasources
â”œâ”€â”€ elk-setup.sh          # Configure ELK stack
â”œâ”€â”€ alerts-setup.sh       # Configure alert rules
â””â”€â”€ README.md
```

**Services Managed**: prometheus, grafana, opensearch, opensearch-dashboards, filebeat

---

## 4. Layer Responsibilities

### Clear Separation of Concerns

| Layer | Primary Responsibility | What It Does | What It Doesn't Do |
|-------|----------------------|--------------|-------------------|
| **Common** | Shared utilities | Logging, Docker ops, validation | No business logic, no service management |
| **Infrastructure** | Foundation services | Start/stop core services, init DBs | No data processing, no ML logic |
| **Data Ingestion** | Data collection | Manage producers/consumers | No data transformation |
| **Storage** | Data lake operations | Bucket management, data lifecycle | No data processing |
| **Processing** | Data transformation | Spark jobs, Bronzeâ†’Silver | No ML training |
| **ML Layer** | Model lifecycle | Training, serving, feature engineering | No data ingestion |
| **Orchestration** | Workflow scheduling | DAG management, pipeline orchestration | No direct service management |
| **Observability** | System monitoring | Metrics, logs, alerts | No application logic |

---

## 5. Service-to-Layer Mapping

### Complete Service Breakdown

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ INFRASTRUCTURE LAYER (Level 0)                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ minio              â†’ Object storage (S3-compatible)           â”‚
â”‚ â€¢ minio-setup        â†’ MinIO initialization container           â”‚
â”‚ â€¢ postgres-mlflow    â†’ MLflow backend store                     â”‚
â”‚ â€¢ postgres-airflow   â†’ Airflow metadata DB                      â”‚
â”‚ â€¢ redis              â†’ Feature store (online serving)           â”‚
â”‚ â€¢ redis-insight      â†’ Redis GUI                                â”‚
â”‚ â€¢ zookeeper          â†’ Kafka coordination                       â”‚
â”‚ â€¢ kafka              â†’ Message broker                           â”‚
â”‚ â€¢ kafka-ui           â†’ Kafka management UI                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ DATA INGESTION LAYER (Level 1)                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ kafka-producer             â†’ Generate synthetic data          â”‚
â”‚ â€¢ kafka-consumer             â†’ Consume to MinIO (Bronze)        â”‚
â”‚ â€¢ clinical-mq                â†’ Clinical message queue           â”‚
â”‚ â€¢ clinical-data-gateway      â†’ Data ingestion gateway           â”‚
â”‚ â€¢ lab-results-processor      â†’ Lab results processing           â”‚
â”‚ â€¢ clinical-data-generator    â†’ Synthetic clinical data          â”‚
â”‚                                                                  â”‚
â”‚ Dependencies: infrastructure                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STORAGE LAYER (Utilities Only)                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ No dedicated services                                          â”‚
â”‚ â€¢ Provides scripts for MinIO operations                         â”‚
â”‚ â€¢ Data lifecycle management (Bronze/Silver/Gold)                â”‚
â”‚                                                                  â”‚
â”‚ Dependencies: infrastructure                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PROCESSING LAYER (Level 2)                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ spark-master       â†’ Spark master node                        â”‚
â”‚ â€¢ spark-worker       â†’ Spark worker node(s)                     â”‚
â”‚ â€¢ spark-streaming    â†’ Real-time processing                     â”‚
â”‚ â€¢ spark-batch        â†’ Batch processing jobs                    â”‚
â”‚                                                                  â”‚
â”‚ Dependencies: infrastructure, data-ingestion                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ML LAYER (Level 3 + 4 Combined)                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ feature-engineering â†’ Feature transformation & storage        â”‚
â”‚ â€¢ mlflow-server       â†’ Experiment tracking & model registry    â”‚
â”‚ â€¢ ml-training         â†’ Model training jobs                     â”‚
â”‚ â€¢ model-serving       â†’ Model inference API                     â”‚
â”‚                                                                  â”‚
â”‚ Dependencies: infrastructure, data-ingestion, processing-layer   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ORCHESTRATION LAYER (Level 5a)                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ airflow-init       â†’ Initialize Airflow                       â”‚
â”‚ â€¢ airflow-webserver  â†’ Airflow UI                               â”‚
â”‚ â€¢ airflow-scheduler  â†’ DAG scheduler                            â”‚
â”‚                                                                  â”‚
â”‚ Dependencies: infrastructure, data-ingestion, processing, ml     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ OBSERVABILITY LAYER (Level 5b)                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ prometheus         â†’ Metrics collection                       â”‚
â”‚ â€¢ grafana            â†’ Metrics visualization                    â”‚
â”‚ â€¢ monitoring-service â†’ Custom monitoring service                â”‚
â”‚ â€¢ opensearch         â†’ Log storage & search                     â”‚
â”‚ â€¢ opensearch-dashboards â†’ Log visualization                     â”‚
â”‚ â€¢ data-prepper       â†’ Log processing                           â”‚
â”‚ â€¢ filebeat           â†’ Log shipping                             â”‚
â”‚                                                                  â”‚
â”‚ Dependencies: ALL previous layers                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 6. Interface Contracts

### Standard Interface for Each Layer

Every `manage.sh` script in each layer MUST implement these commands:

```bash
# Standard operations
./manage.sh start              # Start layer services
./manage.sh start-force        # Force recreate containers
./manage.sh stop               # Stop layer (keep volumes)
./manage.sh stop-full          # Stop layer (remove volumes)
./manage.sh restart            # Restart layer
./manage.sh status             # Show layer status
./manage.sh health             # Run health checks

# Build operations
./manage.sh build              # Build images
./manage.sh rebuild            # Force rebuild images

# Layer-specific operations (optional)
./manage.sh init               # Initialize layer (create configs, etc.)
./manage.sh validate           # Validate layer configuration
./manage.sh logs               # Follow logs for layer services
```

### Communication Protocol

**Layers communicate through:**
1. **Docker Compose profiles** - Defined in config.sh
2. **Dependency declaration** - Each layer declares what it needs
3. **Health checks** - Each layer validates its dependencies
4. **Return codes** - Standard exit codes (0=success, 1=error)

### Example Interface Contract

```bash
# infrastructure/manage.sh MUST provide:
start()        # Start all infrastructure services
stop()         # Stop all infrastructure services
status()       # Return running status
health()       # Validate all services are healthy
init()         # Initialize databases, buckets, topics

# data-ingestion/manage.sh MUST provide:
start()        # Start ingestion services
stop()         # Stop ingestion services
status()       # Return running status
validate()     # Validate Kafka connectivity, etc.
```

---

## 7. Dependency Graph

### Layer Dependency Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Infrastructure    â”‚ â† Level 0 (No dependencies)
â”‚   (Foundation)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚                    â”‚
           â–¼                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Data Ingestion  â”‚   â”‚    Storage     â”‚
â”‚   (Producers)    â”‚   â”‚   (Utilities)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Processing      â”‚
â”‚  (Spark)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ML Layer        â”‚
â”‚  (Training)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                    â”‚
         â–¼                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Orchestration   â”‚   â”‚  Observability   â”‚
â”‚  (Airflow)      â”‚   â”‚  (Monitoring)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Dependency Matrix

| Layer | Depends On |
|-------|-----------|
| infrastructure | (none) |
| data-ingestion | infrastructure |
| storage | infrastructure |
| processing-layer | infrastructure, data-ingestion |
| ml-layer | infrastructure, data-ingestion, processing-layer |
| orchestration-layer | infrastructure, data-ingestion, processing-layer, ml-layer |
| observability | ALL layers |

---

## 8. Migration Strategy

### Phase 1: Extract Common Utilities (Week 1)
- Create `common/utils.sh` with logging, Docker ops
- Create `common/config.sh` with layer definitions
- Create `common/validation.sh` with input validation
- Test common functions in isolation

### Phase 2: Modularize Infrastructure (Week 1-2)
- Extract infrastructure functions to `infrastructure/manage.sh`
- Create MinIO initialization script
- Create Postgres initialization script
- Test infrastructure layer independently

### Phase 3: Modularize Data Pipeline (Week 2)
- Create `data-ingestion/manage.sh`
- Create `processing-layer/manage.sh`
- Test data flow: Ingestion â†’ Processing

### Phase 4: Modularize ML Pipeline (Week 3)
- Create `ml-layer/manage.sh`
- Extract MLflow setup
- Extract feature engineering logic

### Phase 5: Modularize Observability (Week 3)
- Create `orchestration-layer/manage.sh`
- Create `observability/manage.sh`
- Configure monitoring and alerts

### Phase 6: Create Main Orchestrator (Week 4)
- Create `pipeline-manager.sh` (new main entry point)
- Implement cascade logic
- Implement dependency resolution
- Test end-to-end workflows

### Phase 7: Testing & Documentation (Week 4)
- Write integration tests
- Document each layer
- Create usage examples
- Migration guide for users

---

## 9. Success Criteria

### Quantitative Goals
- âœ… No file over 300 lines (current: 1087 lines)
- âœ… Each layer independently testable
- âœ… 90% code reusability through common utilities
- âœ… Clear separation of concerns (0 cross-layer dependencies)

### Qualitative Goals
- âœ… Easy to understand (new dev can understand one layer at a time)
- âœ… Easy to maintain (change in one layer doesn't break others)
- âœ… Easy to extend (add new layer without modifying existing ones)
- âœ… Easy to test (can test layers in isolation)

---

## 10. Next Steps

### Immediate Actions
1. Review and approve this architecture plan
2. Create folder structure
3. Start with Phase 1 (Common utilities)
4. Implement layers incrementally
5. Test each layer before moving to next

### Questions to Answer
- [ ] Do we need any additional layers?
- [ ] Should storage be a separate layer or part of infrastructure?
- [ ] How do we handle configuration files (env vars, secrets)?
- [ ] Do we need a separate testing layer?
- [ ] Should we add a deployment/CI-CD layer?

---

**Ready to proceed?** Once you approve this plan, we'll start implementing phase by phase.
